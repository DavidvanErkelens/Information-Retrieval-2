{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as ss\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from par2vec.common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load tokenized reuters\n",
    "topic2id = np.load('data/reuters/reuters_topic2id.npy').item(0)\n",
    "id2topic = np.load('data/reuters/reuters_id2topic.npy').item(0)\n",
    "topics = list(np.load('data/reuters/reuters_topics.npy'))\n",
    "\n",
    "word2id = np.load('data/reuters/reuters_word2id.npy').item(0)\n",
    "id2word = np.load('data/reuters/reuters_id2word.npy').item(0)\n",
    "tokenized = list(np.load('data/reuters/reuters_tokenized.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute document graphs and essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create graphs for N documents\n",
    "N=100000\n",
    "max_w=13\n",
    "\n",
    "counts = np.zeros((N, max_w))\n",
    "entropies = []\n",
    "for i, (_, A_o, A_i, _, _) in enumerate(get_lapl(tokenized[:N], word2id)):\n",
    "    print ('\\r %d/%d' % (i+1, N), end='')\n",
    "    if (i+1 % 1000) == 0:\n",
    "        print('\\n {}/{} \\n'.format(i, N))\n",
    "        \n",
    "    # Graph\n",
    "    A = (A_o + A_i).data\n",
    "    \n",
    "    # Weight counts\n",
    "    bincount = np.bincount(A.astype(int))\n",
    "    for j in range(min(len(bincount), max_w)):\n",
    "        counts[i, j] = bincount[j]\n",
    "        \n",
    "    # Entropies\n",
    "    entropies.append(sp.stats.entropy((A_o + A_i).data))\n",
    "    \n",
    "\n",
    "# Parse data\n",
    "x = np.arange(1, max_w)\n",
    "y_mean = np.mean(counts[:,1:], axis=0)\n",
    "y_std = np.std(counts[:,1:], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution of non-zero graph weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Distribution of non-zero graph weights')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Average Count')\n",
    "plt.yscale('log')\n",
    "plt.errorbar(x, y_mean, yerr=y_std)\n",
    "plt.savefig('plots/dist_nonzero_graph_weights.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plot distribution graph entropies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Distribution of graph entropies')\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Occurence')\n",
    "sns.distplot(ents, bins=50)\n",
    "plt.savefig('plots/dist_graph_entropies.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plot distribution of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_count = [len(x) for x in topics]\n",
    "plt.xlabel('# Topics per document')\n",
    "plt.ylabel('Amount of Documents')\n",
    "sns.distplot(topic_count, kde=False, )\n",
    "plt.savefig('plots/dist_topics_over_docs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_topics = [item for sublist in topics for item in sublist]\n",
    "topic_i, topic_count = np.unique(flat_topics, return_counts=True)\n",
    "print('Counts per class:', y)\n",
    "plt.bar(x, y)\n",
    "plt.savefig('plots/dist_topic_counts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id2topic[x[np.argmax(y)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch3]",
   "language": "python",
   "name": "conda-env-pytorch3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
